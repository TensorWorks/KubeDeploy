# -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure("2") do |config|
  # Control plane node configuration
  config.vm.define "control_plane", primary: true do |control_plane|
    control_plane.vm.box = "file://../images/kubernetes/control-plane/build/vagrant/packer_k8s-control-plane_virtualbox.box"

    control_plane.vm.hostname = "control-plane.local"
    control_plane.vm.network "private_network", ip: "192.168.56.2"

    control_plane.vm.provision "file", source: "./hack/discover-worker-nodes.sh", destination: "~/KubeDeploy/discover-worker-nodes.sh"

    control_plane.vm.provision "file", source: "./hack/discover-worker-nodes.service", destination: "~/KubeDeploy/discover-worker-nodes.service"

    control_plane.vm.provision "shell", privileged: false, inline: <<-SHELL
      sudo mv ~/KubeDeploy/discover-worker-nodes.service /etc/systemd/system/discover-worker-nodes.service
      sudo systemctl daemon-reload
      sudo systemctl enable discover-worker-nodes
    SHELL

    control_plane.vm.provision "shell", reboot: true

    control_plane.vm.provision "shell", privileged: false, env: {"NODE_IP" => "192.168.56.2"}, inline: <<-SHELL
      ~/KubeDeploy/kubeadm-init.sh

      echo "Environment=\"KUBELET_EXTRA_ARGS=--node-ip=${NODE_IP}\"" | sudo tee -a /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
      sudo systemctl daemon-reload
      sudo systemctl restart kubelet
      sleep 5

      kubectl apply -f ~/KubeDeploy/config

      echo "#!/bin/bash -e" > ~/KubeDeploy/join-cluster.sh
      chmod +x ~/KubeDeploy/join-cluster.sh
      echo -n "sudo " >> ~/KubeDeploy/join-cluster.sh
      kubeadm token create --print-join-command | tr -d "\n" >> ~/KubeDeploy/join-cluster.sh

      mkdir -p /vagrant/.kubedeploy
      cp ~/KubeDeploy/join-cluster.sh /vagrant/.kubedeploy/
    SHELL
  end

  # Linux worker node configuration
  config.vm.define "linux_worker" do |linux_worker|
    linux_worker.vm.box = "file://../images/kubernetes/linux-worker/build/vagrant/packer_k8s-linux-worker_virtualbox.box"

    linux_worker.vm.hostname = "linux-worker.local"
    linux_worker.vm.network "private_network", type: "dhcp"

    linux_worker.vm.provision "shell", privileged: false, env: {"NODE_IP" => "192.168.56.2"}, inline: <<-SHELL
      export IP=$(ip -f inet addr show enp0s8 | awk '/inet / {print $2}' | cut -d "/" -f 1)
      echo -n "${IP}," >> /vagrant/.kubedeploy/pending-worker-nodes.csv
      sleep 2
      
      cp /vagrant/.kubedeploy/join-cluster.sh ~/KubeDeploy/
      ~/KubeDeploy/join-cluster.sh
    SHELL
  end

  # Common settings
  config.ssh.username = "ubuntu"
  config.ssh.password = "ubuntu"
end
